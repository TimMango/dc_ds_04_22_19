{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining and NLP\n",
    "\n",
    "## Part 2\n",
    "\n",
    "### Situation:\n",
    "\n",
    "Priya works at an international PR firm in the Europe division. Their largest client has offices in Ibiza, Madrid, and Las Palmas. She needs to keep her boss aware of current events and provide a weekly short list of articles concerning political events in Spain. The problem is, this takes hours every week to review articles on the BBC and Priya is very busy! She wonders if she could automate this process using text mining to save her time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goal**: to internalize the steps, challenges, and methodology of text mining\n",
    "- explore text analysis by hand\n",
    "- apply text mining steps in Jupyter with Python libraries NLTK\n",
    "- classify documents correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresher on cleaning text\n",
    "![gif](https://www.nyfa.edu/student-resources/wp-content/uploads/2014/10/furious-crazed-typing.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/Mango/anaconda3/lib/python3.7/site-packages (3.3)\n",
      "Requirement already satisfied: six in /Users/Mango/anaconda3/lib/python3.7/site-packages (from nltk) (1.11.0)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk.corpus\n",
    "\n",
    "url_a = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt\"\n",
    "url_b = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/B.txt\"\n",
    "url_c = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/C.txt\"\n",
    "url_d = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/D.txt\"\n",
    "url_e = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/E.txt\"\n",
    "url_f = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/F.txt\"\n",
    "url_g = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/G.txt\"\n",
    "url_h = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/H.txt\"\n",
    "url_i = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/I.txt\"\n",
    "url_j = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/J.txt\"\n",
    "url_k = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/K.txt\"\n",
    "url_l = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/L.txt\"\n",
    "\n",
    "article_a = urllib.request.urlopen(url_a).read()\n",
    "article_b = urllib.request.urlopen(url_b).read()\n",
    "article_c = urllib.request.urlopen(url_c).read()\n",
    "article_d = urllib.request.urlopen(url_d).read()\n",
    "article_e = urllib.request.urlopen(url_e).read()\n",
    "article_f = urllib.request.urlopen(url_f).read()\n",
    "article_g = urllib.request.urlopen(url_g).read()\n",
    "article_h = urllib.request.urlopen(url_h).read()\n",
    "article_i = urllib.request.urlopen(url_i).read()\n",
    "article_j = urllib.request.urlopen(url_j).read()\n",
    "article_k = urllib.request.urlopen(url_k).read()\n",
    "article_l = urllib.request.urlopen(url_l).read()\n",
    "\n",
    "\n",
    "article_a_st = article_a.decode(\"utf-8\")\n",
    "article_b_st = article_b.decode(\"utf-8\")\n",
    "article_c_st = article_c.decode(\"utf-8\")\n",
    "article_d_st = article_d.decode(\"utf-8\")\n",
    "article_e_st = article_f.decode(\"utf-8\")\n",
    "article_a_st = article_a.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Read and Process Article A\n",
    "article_a = urllib.request.urlopen(url_a).read()\n",
    "article_a_st = article_a.decode(\"utf-8\")\n",
    "\n",
    "##\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "arta_tokens_raw = nltk.regexp_tokenize(article_a_st, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Mango/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "arta_tokens_raw = nltk.regexp_tokenize(article_a_st, pattern)\n",
    "\n",
    "# lower case\n",
    "arta_tokens = [i.lower() for i in arta_tokens_raw]\n",
    "\n",
    "# stop words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "arta_tokens_stopped = [w for w in arta_tokens if not w in stop_words]\n",
    "\n",
    "# stem words\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "arta_stemmed = [stemmer.stem(word) for word in arta_tokens_stopped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat w second article\n",
    "article_b = urllib.request.urlopen(url_b).read()\n",
    "article_b_st = article_b.decode(\"utf-8\")\n",
    "artb_tokens_raw = nltk.regexp_tokenize(article_b_st, pattern)\n",
    "artb_tokens = [i.lower() for i in artb_tokens_raw]\n",
    "artb_tokens_stopped = [w for w in artb_tokens if not w in stop_words]\n",
    "artb_stemmed = [stemmer.stem(word) for word in artb_tokens_stopped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what's wrong with the table from yesterday? what does it not consider?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Frequency (DF)\n",
    "\n",
    "$\\begin{align}\n",
    " tf_{i,j} = \\dfrac{n_{i,j}}{\\displaystyle \\sum_k n_{i,j} }\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$\\begin{align}\n",
    "idf(w) = \\log \\dfrac{N}{df_t}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF-IDF score\n",
    "\n",
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The from scratch method\n",
    "![homemade](https://media2.giphy.com/media/LBZcXdG0eVBdK/giphy.gif?cid=3640f6095c2d7bb2526a424a4d97117c)\n",
    "\n",
    "\n",
    "Please go through the code and comment what each section does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Join unique words joined from a and B\n",
    "wordSet = set(arta_stemmed).union(set(artb_stemmed))\n",
    "#Create dictionaries from A and B, count set to 0\n",
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "wordDictB = dict.fromkeys(wordSet, 0) \n",
    "\n",
    "#Count unique words from A\n",
    "for word in arta_stemmed:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "#Count unique words from B\n",
    "for word in artb_stemmed:\n",
    "    wordDictB[word]+=1    \n",
    "\n",
    "#calculate term frequency\n",
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    #empty list\n",
    "    bowCount = len(bow)\n",
    "    #bowcount = values in word dictionary\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "        #word dictionary value count/total number of words in bag of words\n",
    "    return tfDict\n",
    "\n",
    "#Term frequency for both dictionaries\n",
    "tfbowA = computeTF(wordDictA,arta_stemmed)\n",
    "tfbowB = computeTF(wordDictB,artb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ineffici': 0.005434782608695652,\n",
       " 'mep': 0.010869565217391304,\n",
       " 'action': 0.005434782608695652,\n",
       " 'disast': 0.0,\n",
       " 'sign': 0.0,\n",
       " 'line': 0.005434782608695652,\n",
       " 'exampl': 0.005434782608695652,\n",
       " 'gain': 0.005434782608695652,\n",
       " 'say': 0.016304347826086956,\n",
       " 'two': 0.010869565217391304,\n",
       " 'wealthi': 0.0,\n",
       " 'law': 0.02717391304347826,\n",
       " 'final': 0.0,\n",
       " 'would': 0.016304347826086956,\n",
       " 'invent': 0.02717391304347826,\n",
       " 'reach': 0.0,\n",
       " 'later': 0.0,\n",
       " 'begun': 0.0,\n",
       " 'meet': 0.005434782608695652,\n",
       " 'fuller': 0.005434782608695652,\n",
       " 'juri': 0.010869565217391304,\n",
       " 'said': 0.010869565217391304,\n",
       " 'jack': 0.0,\n",
       " 'critic': 0.010869565217391304,\n",
       " 'announc': 0.0,\n",
       " 'affair': 0.005434782608695652,\n",
       " 'agreement': 0.0,\n",
       " 'propos': 0.010869565217391304,\n",
       " 'brown': 0.0,\n",
       " 'financ': 0.0,\n",
       " 'freez': 0.0,\n",
       " 'similar': 0.005434782608695652,\n",
       " 'reconstruct': 0.0,\n",
       " 'friday': 0.0,\n",
       " 'govern': 0.005434782608695652,\n",
       " 'britain': 0.0,\n",
       " 'without': 0.005434782608695652,\n",
       " 'state': 0.010869565217391304,\n",
       " 'year': 0.0,\n",
       " 'suffer': 0.005434782608695652,\n",
       " 'innov': 0.005434782608695652,\n",
       " 'also': 0.0,\n",
       " 'expect': 0.0,\n",
       " 'us': 0.016304347826086956,\n",
       " 'direct': 0.021739130434782608,\n",
       " 'rewrit': 0.005434782608695652,\n",
       " 'larg': 0.005434782608695652,\n",
       " 'fight': 0.005434782608695652,\n",
       " 'achiev': 0.005434782608695652,\n",
       " 'face': 0.0,\n",
       " 'foreign': 0.0,\n",
       " 'fund': 0.0,\n",
       " 'even': 0.005434782608695652,\n",
       " 'save': 0.0,\n",
       " 'chair': 0.0,\n",
       " 'deal': 0.0,\n",
       " 'click': 0.005434782608695652,\n",
       " 'secretari': 0.0,\n",
       " 'rule': 0.005434782608695652,\n",
       " 'earlier': 0.0,\n",
       " 'problem': 0.0,\n",
       " 'model': 0.005434782608695652,\n",
       " 'debt': 0.0,\n",
       " 'put': 0.005434782608695652,\n",
       " 'mean': 0.005434782608695652,\n",
       " 'hurt': 0.005434782608695652,\n",
       " 'interest': 0.0,\n",
       " 'oppon': 0.005434782608695652,\n",
       " 'reboot': 0.005434782608695652,\n",
       " 'affect': 0.0,\n",
       " 'idea': 0.0,\n",
       " 'member': 0.010869565217391304,\n",
       " 'come': 0.0,\n",
       " 'intend': 0.005434782608695652,\n",
       " 'com': 0.005434782608695652,\n",
       " 'favour': 0.005434782608695652,\n",
       " 'shop': 0.005434782608695652,\n",
       " 'briton': 0.0,\n",
       " 'effect': 0.005434782608695652,\n",
       " 'welcom': 0.005434782608695652,\n",
       " 'miss': 0.0,\n",
       " 'mr': 0.0,\n",
       " 'poland': 0.005434782608695652,\n",
       " 'world': 0.0,\n",
       " 'twice': 0.005434782608695652,\n",
       " 'countri': 0.0,\n",
       " 'new': 0.010869565217391304,\n",
       " 'momentum': 0.005434782608695652,\n",
       " 'might': 0.005434782608695652,\n",
       " 'night': 0.0,\n",
       " 'firm': 0.010869565217391304,\n",
       " 'debat': 0.005434782608695652,\n",
       " 'one': 0.016304347826086956,\n",
       " 'busi': 0.005434782608695652,\n",
       " 'concern': 0.005434782608695652,\n",
       " 'group': 0.0,\n",
       " 'implic': 0.005434782608695652,\n",
       " 'implement': 0.010869565217391304,\n",
       " 'immens': 0.005434782608695652,\n",
       " 'controversi': 0.005434782608695652,\n",
       " 'submit': 0.005434782608695652,\n",
       " 'abstain': 0.005434782608695652,\n",
       " 'lead': 0.005434782608695652,\n",
       " 'court': 0.005434782608695652,\n",
       " 'permit': 0.005434782608695652,\n",
       " 'minist': 0.0,\n",
       " 'canada': 0.0,\n",
       " 'decis': 0.005434782608695652,\n",
       " 'support': 0.010869565217391304,\n",
       " 'bank': 0.0,\n",
       " 'germani': 0.0,\n",
       " 'gordon': 0.0,\n",
       " 'back': 0.010869565217391304,\n",
       " 'program': 0.005434782608695652,\n",
       " 'europ': 0.005434782608695652,\n",
       " 'order': 0.010869565217391304,\n",
       " 'japan': 0.0,\n",
       " 'intens': 0.005434782608695652,\n",
       " 'eu': 0.021739130434782608,\n",
       " 'servic': 0.005434782608695652,\n",
       " 'reject': 0.005434782608695652,\n",
       " 'lock': 0.0,\n",
       " 'adopt': 0.005434782608695652,\n",
       " 'method': 0.005434782608695652,\n",
       " 'pressur': 0.005434782608695652,\n",
       " 'open': 0.005434782608695652,\n",
       " 'lobbi': 0.005434782608695652,\n",
       " 'small': 0.010869565217391304,\n",
       " 'develop': 0.005434782608695652,\n",
       " 'word': 0.005434782608695652,\n",
       " 'pound': 0.0,\n",
       " 'complet': 0.0,\n",
       " 'protect': 0.010869565217391304,\n",
       " 'week': 0.0,\n",
       " 'play': 0.005434782608695652,\n",
       " 'dead': 0.0,\n",
       " 'thought': 0.0,\n",
       " 'first': 0.005434782608695652,\n",
       " 'comput': 0.021739130434782608,\n",
       " 'talk': 0.0,\n",
       " 'monetari': 0.0,\n",
       " 'legal': 0.016304347826086956,\n",
       " 'union': 0.005434782608695652,\n",
       " 'commiss': 0.005434782608695652,\n",
       " 'tsunami': 0.0,\n",
       " 'chanc': 0.005434782608695652,\n",
       " 'parliament': 0.010869565217391304,\n",
       " 'hit': 0.0,\n",
       " 'current': 0.005434782608695652,\n",
       " 'draft': 0.016304347826086956,\n",
       " 'agre': 0.0,\n",
       " 'start': 0.005434782608695652,\n",
       " 'read': 0.005434782608695652,\n",
       " 'hold': 0.005434782608695652,\n",
       " 'amazon': 0.005434782608695652,\n",
       " 'fear': 0.005434782608695652,\n",
       " 'serv': 0.005434782608695652,\n",
       " 'impact': 0.005434782608695652,\n",
       " 'vote': 0.005434782608695652,\n",
       " 'let': 0.005434782608695652,\n",
       " 'vocal': 0.005434782608695652,\n",
       " 'sourc': 0.005434782608695652,\n",
       " 'happen': 0.005434782608695652,\n",
       " 'month': 0.005434782608695652,\n",
       " 'internet': 0.005434782608695652,\n",
       " 'larger': 0.005434782608695652,\n",
       " 'softwar': 0.016304347826086956,\n",
       " 'bring': 0.005434782608695652,\n",
       " 'offer': 0.005434782608695652,\n",
       " 'setback': 0.005434782608695652,\n",
       " 'hammer': 0.0,\n",
       " 'compani': 0.005434782608695652,\n",
       " 'creditor': 0.0,\n",
       " 'straw': 0.0,\n",
       " 'number': 0.0,\n",
       " 'bn': 0.0,\n",
       " 'moratorium': 0.0,\n",
       " 'base': 0.010869565217391304,\n",
       " 'financi': 0.005434782608695652,\n",
       " 'issu': 0.005434782608695652,\n",
       " 'largest': 0.005434782608695652,\n",
       " 'could': 0.016304347826086956,\n",
       " 'thursday': 0.0,\n",
       " 'believ': 0.0,\n",
       " 'suspend': 0.0,\n",
       " 'give': 0.005434782608695652,\n",
       " 'field': 0.005434782608695652,\n",
       " 'g': 0.0,\n",
       " 'fail': 0.005434782608695652,\n",
       " 'committe': 0.010869565217391304,\n",
       " 'nation': 0.005434782608695652,\n",
       " 'chancellor': 0.0,\n",
       " 'european': 0.010869565217391304,\n",
       " 'biggest': 0.0,\n",
       " 'repay': 0.0,\n",
       " 'patent': 0.02717391304347826,\n",
       " 'instruct': 0.0,\n",
       " 'use': 0.005434782608695652,\n",
       " 'hope': 0.0,\n",
       " 'intern': 0.0,\n",
       " 'analysi': 0.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA = computeTFIDF(tfbowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfbowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>affect</th>\n",
       "      <th>agre</th>\n",
       "      <th>agreement</th>\n",
       "      <th>also</th>\n",
       "      <th>amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>wealthi</th>\n",
       "      <th>week</th>\n",
       "      <th>welcom</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
       "0  0.001636  0.001636  0.001636  0.001636  0.001636  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.002923  0.002923   \n",
       "\n",
       "   agreement      also    amazon    ...        vocal      vote   wealthi  \\\n",
       "0   0.000000  0.000000  0.001636    ...     0.001636  0.001636  0.000000   \n",
       "1   0.002923  0.005845  0.000000    ...     0.000000  0.000000  0.002923   \n",
       "\n",
       "       week    welcom   without      word     world  would      year  \n",
       "0  0.000000  0.001636  0.001636  0.001636  0.000000    0.0  0.000000  \n",
       "1  0.002923  0.000000  0.000000  0.000000  0.002923    0.0  0.002923  \n",
       "\n",
       "[2 rows x 201 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([tfidfBowA, tfidfBowB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But yes, there is an easier way\n",
    "\n",
    "![big deal](https://media0.giphy.com/media/xUA7aQOxkz00lvCAOQ/giphy.gif?cid=3640f6095c2d7c51772f47644d09cc8b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
      "0  0.053285  0.053285  0.053285  0.053285  0.053285  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.084167  0.084167   \n",
      "\n",
      "   agreement      also    amazon    ...        vocal      vote   wealthi  \\\n",
      "0   0.000000  0.000000  0.053285    ...     0.053285  0.053285  0.000000   \n",
      "1   0.084167  0.168334  0.000000    ...     0.000000  0.000000  0.084167   \n",
      "\n",
      "       week    welcom   without      word     world     would      year  \n",
      "0  0.000000  0.053285  0.053285  0.053285  0.000000  0.113738  0.000000  \n",
      "1  0.084167  0.000000  0.000000  0.000000  0.084167  0.059885  0.084167  \n",
      "\n",
      "[2 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a string again\n",
    "cleaned_a = ' '.join(arta_stemmed)\n",
    "cleaned_b = ' '.join(artb_stemmed)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform([cleaned_a, cleaned_b])\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics \n",
    "\n",
    "How many non-zero elements are there?\n",
    "- Adapt the code below, using the `df` version of the `response` object to replace everywhere below it says `DATA`\n",
    "- Interpret the findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-06e3e32b7671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Edit code before running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnon_zero_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average Number of Non-Zero Elements in Vectorized Articles: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_zero_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATA' is not defined"
     ]
    }
   ],
   "source": [
    "# Edit code before running it\n",
    "\n",
    "non_zero_cols = DATA.nnz / float(DATA.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(DATA.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "- Create the tf-idf for the **whole** corpus of 12 articles\n",
    "- What are _on average_ the most important words in the whole corpus?\n",
    "- Add a column named \"Target\" to the dataset\n",
    "- Target will be set to 1 or 0 if the article is \"Politics\" or \"Not Politics\"\n",
    "- Do some exploratory analysis of the dataset\n",
    " - what are the average most important words for the \"Politics\" articles?\n",
    " - What are the average most important words for the \"Not Politics\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets talk classification\n",
    "- How would you split into train and test? what would be the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
